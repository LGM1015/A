import streamlit as st
from openai import OpenAI

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="ç­‘æ¢¦æ™ºèƒ½ä½“ (Real AI)", page_icon="ğŸ§ ", layout="wide")

# --- ä¾§è¾¹æ ï¼šé…ç½®â€œå¤§è„‘â€ ---
with st.sidebar:
    st.title("âš™ï¸ å¼€å‘æ§åˆ¶å°")
    st.markdown("è¿™æ˜¯**äºŒé˜¶å®è®­**çš„æ ¸å¿ƒï¼šé…ç½®æ¨¡å‹å‚æ•°ã€‚")
    # API é…ç½®
    api_key = st.text_input("API Key", type="password", help="OpenAI æˆ– DeepSeek çš„ Key")
    # è‡ªåŠ¨å¤„ç† Base URLï¼Œé˜²æ­¢å°ç™½å¡«é”™
    provider = st.selectbox("é€‰æ‹©æœåŠ¡å•†", ["OpenAI", "DeepSeek", "è‡ªå®šä¹‰"])

    if provider == "OpenAI":
        base_url = "https://api.openai.com/v1"
        default_model = "gpt-3.5-turbo"
    elif provider == "DeepSeek":
        base_url = "https://api.deepseek.com"  # DeepSeek å®˜æ–¹å…¼å®¹åœ°å€
        default_model = "deepseek-chat"
    else:
        base_url = st.text_input("Base URL", value="https://api.openai.com/v1")
        default_model = "gpt-3.5-turbo"
    model_name = st.text_input("æ¨¡å‹åç§°", value=default_model)

    # 2. è§’è‰²è®¾å®š (Prompt Engineering)
    st.divider()
    system_prompt = st.text_area(
        "ç³»ç»Ÿæç¤ºè¯ (System Prompt)",
        value="ä½ æ˜¯ç”±åˆ›é¹¤æ™ºèƒ½å¼€å‘çš„â€œç­‘æ¢¦â€æ ¡å›­åŠ©æ‰‹ã€‚è¯·ç”¨äº²åˆ‡ã€ä¸“ä¸šçš„è¯­æ°”å›ç­”å­¦ç”Ÿå…³äºAIå®è®­çš„é—®é¢˜ã€‚",
        height=100
    )

    # 3. æ¸…ç©ºè®°å¿†
    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå¯¹è¯å†å²"):
        st.session_state.messages = []
        st.rerun()

# --- åˆå§‹åŒ– ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- èŠå¤©ä¸»ç•Œé¢ ---
st.title("ğŸ§  ç­‘æ¢¦çœŸå® AI åŠ©æ‰‹")
st.caption("ğŸš€ å·²è¿æ¥çœŸå®å¤§æ¨¡å‹ API | æ”¯æŒå¤šè½®å¯¹è¯ä¸æµå¼è¾“å‡º")

# 1. æ¸²æŸ“å†å²æ¶ˆæ¯
for msg in st.session_state.messages:
    # ä¸æ˜¾ç¤º system promptï¼Œåªæ˜¾ç¤º user å’Œ assistant
    if msg["role"] != "system":
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

# 2. å¤„ç†ç”¨æˆ·è¾“å…¥
if prompt := st.chat_input("é—®æˆ‘ä»»ä½•é—®é¢˜..."):
    if not api_key:
        st.warning("âš ï¸ è¯·å…ˆåœ¨å·¦ä¾§ä¾§è¾¹æ è¾“å…¥ API Key æ‰èƒ½å¯åŠ¨å¤§è„‘ï¼")
        st.stop()

    # æ˜¾ç¤ºç”¨æˆ·æé—®
    with st.chat_message("user"):
        st.markdown(prompt)

    # æ„å»ºå®Œæ•´çš„æ¶ˆæ¯ä¸Šä¸‹æ–‡ (System Prompt + History + Current Prompt)
    # è¿™ä¸€æ­¥éå¸¸é‡è¦ï¼Œä¿è¯ AI è®°å¾—ä½ä¹‹å‰çš„å¯¹è¯
    messages_payload = [{"role": "system", "content": system_prompt}] + \
                       [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages] + \
                       [{"role": "user", "content": prompt}]

    # å­˜å…¥ session ç”¨äºæ˜¾ç¤º
    st.session_state.messages.append({"role": "user", "content": prompt})

    # 3. è°ƒç”¨çœŸå® API å¹¶æµå¼è¾“å‡º
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        full_response = ""

        try:
            # åˆå§‹åŒ–å®¢æˆ·ç«¯
            client = OpenAI(api_key=api_key, base_url=base_url)

            # å‘èµ·è¯·æ±‚ (å¼€å¯ stream=True å®ç°æ‰“å­—æœºæ•ˆæœ)
            stream = client.chat.completions.create(
                model=model_name,
                messages=messages_payload,
                stream=True,
                temperature=0.7
            )

            # å®æ—¶æ¥æ”¶æ•°æ®å—
            for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    content = chunk.choices[0].delta.content
                    full_response += content
                    message_placeholder.markdown(full_response + "â–Œ")

            message_placeholder.markdown(full_response)

            # å°† AI çš„å›å¤å­˜å…¥å†å²ï¼Œå½¢æˆé—­ç¯
            st.session_state.messages.append({"role": "assistant", "content": full_response})

        except Exception as e:
            st.error(f"âŒ è°ƒç”¨å¤±è´¥: {e}")